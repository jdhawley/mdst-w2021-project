{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "promising-windows",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (1.20.1)\n",
      "Requirement already satisfied: pandas in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: geopandas in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: requests in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from beautifulsoup4) (2.2)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from geopandas) (3.0.1)\n",
      "Requirement already satisfied: shapely>=1.6 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from geopandas) (1.7.1)\n",
      "Requirement already satisfied: fiona>=1.8 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from geopandas) (1.8.18)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: attrs>=17 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
      "Requirement already satisfied: certifi in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2020.12.5)\n",
      "Requirement already satisfied: click<8,>=4.0 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (0.7.1)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: six>=1.7 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
      "Requirement already satisfied: munch in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from requests) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/jonathanhawley/mdst/env/lib/python3.9/site-packages (from requests) (2.10)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy pandas geopandas requests beautifulsoup4\n",
    "\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import geopandas as gpd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dramatic-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure settings values\n",
    "data_dir = '/Volumes/EXTERNAL/mdst_data'\n",
    "pull_zip_files = False\n",
    "process_zip_files = False\n",
    "combine_zip_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "alternative-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcode namespaces for xml processing\n",
    "ns = {'gmx':\"http://www.isotc211.org/2005/gmx\",\n",
    "      'gco':\"http://www.isotc211.org/2005/gco\",\n",
    "      'gmd':\"http://www.isotc211.org/2005/gmd\",\n",
    "      'xlink':\"http://www.w3.org/1999/xlink\",\n",
    "      'gml':\"http://www.opengis.net/gml/3.2\",\n",
    "      'xsi':\"http://www.w3.org/2001/XMLSchema-instance\",\n",
    "      'gfc':\"http://www.isotc211.org/2005/gfc\"}\n",
    "\n",
    "def read_xml(filename):\n",
    "    # Read in xml data from file\n",
    "    with open(filename) as fp:\n",
    "        xml = ET.fromstring(fp.read())\n",
    "\n",
    "    # Get all listed features\n",
    "    features = [e for e in xml.iter() if e.find('./gfc:memberName/gco:LocalName', ns) is not None]\n",
    "\n",
    "    # Retrieve the route types and feature class codes from the listed features\n",
    "    for feature in features:\n",
    "        if feature.find('./gfc:memberName/gco:LocalName', ns).text == 'RTTYP':\n",
    "            route_type_codes = list(map(lambda x: x.text,\n",
    "                                        feature.findall('./gfc:listedValue/gfc:FC_ListedValue/gfc:label/gco:CharacterString', ns)))\n",
    "            route_type_values = list(map(lambda x: x.text,\n",
    "                                         feature.findall('./gfc:listedValue/gfc:FC_ListedValue/gfc:definition/gco:CharacterString', ns)))\n",
    "            route_types = pd.DataFrame({'route_type_code':route_type_codes, 'route_type':route_type_values})\n",
    "        elif feature.find('./gfc:memberName/gco:LocalName', ns).text == 'MTFCC':\n",
    "            feature_class_codes = feature.findall('./gfc:listedValue', ns)\n",
    "            mtfcc_codes = list(map(lambda x: x.text,\n",
    "                                        feature.findall('./gfc:listedValue/gfc:FC_ListedValue/gfc:label/gco:CharacterString', ns)))\n",
    "            mtfcc_values = list(map(lambda x: x.text,\n",
    "                                         feature.findall('./gfc:listedValue/gfc:FC_ListedValue/gfc:definition/gco:CharacterString', ns)))\n",
    "            mtfcc = pd.DataFrame({'mtfcc_code':mtfcc_codes, 'mtfcc':mtfcc_values})\n",
    "            \n",
    "    return (route_types, mtfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "pressing-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pull_zip_files:\n",
    "    # Get the HTML to scrape for zip files\n",
    "    url = 'https://www2.census.gov/geo/tiger/TIGER2019/ROADS/'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Pull all the zip files\n",
    "    filenames = [a.text.rstrip('.zip') for a in soup.find_all('a') if 'tl_2019_' in a.text]\n",
    "    for i in range(len(filenames)):\n",
    "        full_path = data_dir + '/zips/' + filenames[i] + '.zip'\n",
    "        if not os.path.isfile(full_path):\n",
    "            content = requests.get(url + filenames[i] + '.zip', allow_redirects=True).content\n",
    "            with open(full_path, 'wb') as writer:\n",
    "                writer.write(content)\n",
    "\n",
    "        if ((i+1) % 10 == 0): print(str(i+1) + ' zip files pulled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "advance-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "if process_zip_files:\n",
    "    metadata_route_types = None\n",
    "    metadata_mtfcc = None\n",
    "    for i in range(len(filenames)):\n",
    "        # Define local paths\n",
    "        full_zip_path = data_dir + '/zips/' + filenames[i] + '.zip'\n",
    "        folder_path = data_dir + '/' + filenames[i]\n",
    "        metadata_file_path = folder_path + '/' + filenames[i] + '.shp.ea.iso.xml'\n",
    "        shapefile_file_path = folder_path + '/' + filenames[i] + '.shp'\n",
    "        final_csv_path = data_dir + '/csv/' + filenames[i] + '.csv'\n",
    "\n",
    "        if not os.path.isfile(final_csv_path):\n",
    "            # Extract the zip locally\n",
    "            with zipfile.ZipFile(full_zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(folder_path)\n",
    "\n",
    "            # Extract metadata from .shp.ea.iso.xml file\n",
    "            route_types, mtfcc = read_xml(metadata_file_path)\n",
    "            metadata_route_types = route_types.copy() if metadata_route_types is None else metadata_route_types.append(route_types).drop_duplicates()\n",
    "            metadata_mtfcc = mtfcc.copy() if metadata_mtfcc is None else metadata_mtfcc.append(mtfcc).drop_duplicates()\n",
    "\n",
    "            # Pull data from shapefile and merge into single df\n",
    "            shapefile = gpd.read_file(shapefile_file_path)\n",
    "            shapefile = shapefile.drop(['LINEARID', 'geometry'], axis=1)\n",
    "            shapefile.columns = ['full_name', 'route_type_code', 'mtfcc_code']\n",
    "\n",
    "            # Save the data to a csv that can be loaded later\n",
    "            shapefile.to_csv(final_csv_path, index=False)\n",
    "\n",
    "            # Delete folder with unzipped data\n",
    "            shutil.rmtree(folder_path)\n",
    "\n",
    "        if ((i+1) % 10 == 0): print(str(i+1) + ' zip files processed')\n",
    "\n",
    "    if metadata_route_types is not None: metadata_route_types.to_csv(data_dir + '/csv/metadata_route_types.csv', index=False)\n",
    "    if metadata_mtfcc is not None: metadata_mtfcc.to_csv(data_dir + '/csv/metadata_mtfcc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "revolutionary-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 csv files processed\n",
      "200 csv files processed\n",
      "300 csv files processed\n",
      "400 csv files processed\n",
      "500 csv files processed\n",
      "600 csv files processed\n",
      "700 csv files processed\n",
      "800 csv files processed\n",
      "900 csv files processed\n",
      "1000 csv files processed\n",
      "1100 csv files processed\n",
      "1200 csv files processed\n",
      "1300 csv files processed\n",
      "1400 csv files processed\n",
      "1500 csv files processed\n",
      "1600 csv files processed\n",
      "1700 csv files processed\n",
      "1800 csv files processed\n",
      "1900 csv files processed\n",
      "2000 csv files processed\n",
      "2100 csv files processed\n",
      "2200 csv files processed\n",
      "2300 csv files processed\n",
      "2400 csv files processed\n",
      "2500 csv files processed\n",
      "2600 csv files processed\n",
      "2700 csv files processed\n",
      "2800 csv files processed\n",
      "2900 csv files processed\n",
      "3000 csv files processed\n",
      "3100 csv files processed\n",
      "3200 csv files processed\n",
      "CPU times: user 16min 42s, sys: 6min 11s, total: 22min 54s\n",
      "Wall time: 24min 38s\n"
     ]
    }
   ],
   "source": [
    "# Read in metadata\n",
    "metadata_route_types = pd.read_csv(data_dir + '/csv/metadata_route_types.csv')\n",
    "metadata_mtfcc = pd.read_csv(data_dir + '/csv/metadata_mtfcc.csv')\n",
    "\n",
    "if combine_road_data:\n",
    "    # Combine all road data into single csv\n",
    "    df = None\n",
    "    csv_filenames = [fn for fn in os.listdir(data_dir + '/csv') if 'tl_2019_' in fn]\n",
    "    for i in range(len(csv_filenames)):\n",
    "        zip_code = filenames[i].split('_')[2]\n",
    "        csv_data = pd.read_csv(data_dir + '/csv/' + csv_filenames[i])\n",
    "        csv_data['zip'] = zip_code\n",
    "\n",
    "        if df is None:\n",
    "            df = csv_data.copy()\n",
    "        else:\n",
    "            df = df.append(csv_data, ignore_index=True)\n",
    "\n",
    "        if ((i+1) % 100 == 0): print(str(i+1) + ' csv files processed')\n",
    "        \n",
    "    #display(df)\n",
    "    df.to_csv(data_dir + '/master_road_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-career",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
